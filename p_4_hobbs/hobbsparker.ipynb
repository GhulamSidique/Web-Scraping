{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import  WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd \n",
    "import time\n",
    "import os\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape(path):\n",
    "#     options = ChromeOptions()\n",
    "#     options.headless=True\n",
    "#     service = Service(r\"E:\\web_scarping\\project_4_hobbs\\chromedriver.exe\")\n",
    "#     driver = Chrome(service=service, options=options)\n",
    "#     driver.get(path)\n",
    "\n",
    "# # ==========================================================================================\n",
    "#     # get the cookies acceptance button and click on it\n",
    "#     try:\n",
    "#         cookie = driver.find_element(By.CSS_SELECTOR, \".t-acceptAllButton\")\n",
    "#         cookie.click()\n",
    "#     except Exception as e:\n",
    "#         print(f\"No cookie found and the error is {e}\")\n",
    "\n",
    "# # ==========================================================================================\n",
    "#     results = [] # to append the details\n",
    "\n",
    "#     # get the car link and click on it\n",
    "#     try:\n",
    "#         # get the links \n",
    "#         car_links = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a[title='view more photos']\")))\n",
    "#         car_links[0].click()\n",
    "\n",
    "#         # loop around the number of links found\n",
    "#         for i in range(10): #len(car_links)\n",
    "#         # ==========================================================================================\n",
    "#             # get the car section to extract the following information\n",
    "#             try:\n",
    "#                 # get the car info complete section\n",
    "#                 car_info_section = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"section.o-section--light-gray\")))\n",
    "\n",
    "#             # ==========================================================================================\n",
    "#                 # dictionary to save the data\n",
    "#                 details = {}\n",
    "#                 # get the car make, model, type and color\n",
    "#                 try:\n",
    "#                     car_details = car_info_section.find_element(By.CSS_SELECTOR, \"h3.o-lot__subheading\").text # here we will have car make, model, VEHCILE type, colour\n",
    "#                     if car_details:\n",
    "#                         # split the data\n",
    "#                         splited_data = [item.strip() for item in car_details.split(' / ')]\n",
    "#                         # append the data into the dictionary\n",
    "#                         details['Car_make'] = splited_data[0]\n",
    "#                         details['Car_model'] = splited_data[1]\n",
    "#                         details['Veh_type'] = splited_data[2]\n",
    "#                         details['Car_colour'] = splited_data[3]\n",
    "#                     else:\n",
    "#                         print(\"No car details found\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"No car details tab found and error is {e}\")\n",
    "#                     # details['Car_description'] = 'No car description found]'\n",
    "                \n",
    "#             # ==========================================================================================\n",
    "#                 # get the car services\n",
    "#                 try:\n",
    "#                     # get the section\n",
    "#                     desc =WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.m-caslot__description\")))\n",
    "#                     if desc:\n",
    "#                         car_serv =desc.find_elements(By.TAG_NAME, \"p\")\n",
    "#                         details[\"Car_features \"] = car_serv[1].text\n",
    "#                     else:\n",
    "#                         details[\"Car_features \"] = \"N/A\"\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"No car features found and error is {e}\")\n",
    "\n",
    "#             # ==========================================================================================\n",
    "#                 # get the service history\n",
    "#                 try:\n",
    "#                     main_card =driver.find_element(By.CSS_SELECTOR, \"div.o-lot__features\")\n",
    "#                     if main_card:\n",
    "#                         li_elements = main_card.find_elements(By.CSS_SELECTOR, 'ul.m-caslot__features li')\n",
    "#                         if li_elements:\n",
    "#                             li_list = []\n",
    "#                             for ele in li_elements:\n",
    "#                                 # li_text = ele.text.strip()\n",
    "#                                 li_list.append(ele.text.strip())\n",
    "#                             details[\"car_Details\"] = li_list\n",
    "#                         else:\n",
    "#                             details[\"car_Details\"] = \"N/A\"\n",
    "#                     else:\n",
    "#                         print(\"No car feature main card found\")\n",
    "                    \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"No car details found and error is {e}\")\n",
    "\n",
    "#             # ==========================================================================================\n",
    "#                 # get the lot number and auction details\n",
    "#                 try:\n",
    "#                     lot_center = driver.find_element(By.CSS_SELECTOR, \".m-lot-overview__lotno\").text\n",
    "#                     if lot_center:\n",
    "#                         lot_split = [lot_item.strip() for lot_item in lot_center.split(\" – \")]\n",
    "#                         details[\"Lot\"] = lot_split[0]\n",
    "#                         details['Reg_no'] = lot_split[1]\n",
    "#                     else:\n",
    "#                         print(\"No car lot and reg no found\")\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"No car lot and reg no found and error is {e}\")\n",
    "\n",
    "#             # ==========================================================================================\n",
    "#                 # get the auction details\n",
    "#                 try:\n",
    "#                     # get the auction detail\n",
    "#                     auc_details = driver.find_elements(By.CSS_SELECTOR, \"p.m-lot-overview__info\")\n",
    "#                     if auc_details:\n",
    "#                         details[\"Auction_details\"] = auc_details[0].text\n",
    "#                     else:\n",
    "#                         details[\"Auction_details\"] = \"N/A\"\n",
    "\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"No car auction details found\")\n",
    "\n",
    "#             # ==========================================================================================\n",
    "#                 # get the car images\n",
    "#                 try:\n",
    "#                     # Find all <img> elements within divs that have class 'slick-slide'\n",
    "#                     img_list = []\n",
    "#                     img_elements = driver.find_elements(By.CSS_SELECTOR, 'div.slick-slide img')\n",
    "#                     if img_elements:\n",
    "#                         for i in img_elements:\n",
    "#                             img_list.append(i.get_attribute(\"src\"))\n",
    "#                         img_str = \", \".join(img_list)\n",
    "#                         details[\"Images\"] = img_str\n",
    "#                     else:\n",
    "#                         details[\"Images\"] = \"N/A\"\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"No car images found and error is {e}\")\n",
    "#             # ==========================================================================================\n",
    "#             # ==========================================================================================\n",
    "\n",
    "#                 results.append(details)\n",
    "#                 # Click on each link\n",
    "#                 driver.back()\n",
    "#                 # refetch the links\n",
    "#                 # car_links\n",
    "#                 car_links = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a[title='view more photos']\")))\n",
    "#                 if car_links:\n",
    "#                     car_links[i].click()\n",
    "#                 else:\n",
    "#                     print(\"No more car links available\")\n",
    "\n",
    "#         # ==========================================================================================\n",
    "#         # ==========================================================================================   \n",
    "\n",
    "#             except Exception as e:\n",
    "#                 print(f\"No car info section found and error is {e}\")\n",
    "\n",
    "#         # ==========================================================================================\n",
    "#         # ==========================================================================================\n",
    "\n",
    "#             # # Click on each link\n",
    "#             # driver.back()\n",
    "#             # # refetch the links\n",
    "#             # # car_links\n",
    "#             # car_links = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a[title='view more photos']\")))\n",
    "#             # car_links[i].click()\n",
    "            \n",
    "#     # ==========================================================================================\n",
    "#     # ========================================================================================== \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(\"No car links found\")\n",
    "    \n",
    "#     # ==========================================================================================\n",
    "#     # ==========================================================================================\n",
    "\n",
    "#     df = pd.DataFrame.from_dict(results)\n",
    "#     df.to_csv(\"HOOBS.csv\")\n",
    "\n",
    "\n",
    "#     driver.quit()\n",
    "#     # print(results)\n",
    "# path = \"https://www.hobbsparker.co.uk/car-auctions/auction-dates/catalogue/?departmentId=8&saleTypeId=5&auctionId=456218\"\n",
    "# scrape(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape(path):\n",
    "    # Chrome options\n",
    "    options = ChromeOptions()\n",
    "    options.headless = True\n",
    "    service = Service(r\"E:\\web_scarping\\project_4_hobbs\\chromedriver.exe\")\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.get(path)\n",
    "\n",
    "    # Accept cookies\n",
    "    try:\n",
    "        cookie = driver.find_element(By.CSS_SELECTOR, \".t-acceptAllButton\")\n",
    "        cookie.click()\n",
    "    except Exception as e:\n",
    "        print(f\"No cookie button found: {e}\")\n",
    "\n",
    "    results = []  # List to store all car details\n",
    "\n",
    "    try:\n",
    "        # Get the car links\n",
    "        car_links = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a[title='view more photos']\")))\n",
    "\n",
    "        # Loop through car links\n",
    "        for i in range(5): #len(car_links)\n",
    "            try:\n",
    "                # Refresh the car links after navigating back\n",
    "                car_links = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a[title='view more photos']\")))\n",
    "\n",
    "                # Click the current car link\n",
    "                car_links[i].click()\n",
    "\n",
    "                # Dictionary to store car details\n",
    "                details = {}\n",
    "\n",
    "                # Extract car details\n",
    "                try:\n",
    "                    car_info_section = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"section.o-section--light-gray\")))\n",
    "\n",
    "                    car_details = car_info_section.find_element(By.CSS_SELECTOR, \"h3.o-lot__subheading\").text\n",
    "                    if car_details:\n",
    "                        splited_data = [item.strip() for item in car_details.split(' / ')]\n",
    "                        details['Car_make'] = splited_data[0]\n",
    "                        details['Car_model'] = splited_data[1]\n",
    "                        details['Veh_type'] = splited_data[2]\n",
    "                        details['Car_colour'] = splited_data[3]\n",
    "                    else:\n",
    "                        details['Car_make'] = details['Car_model'] = details['Veh_type'] = details['Car_colour'] = \"N/A\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting car details: {e}\")\n",
    "\n",
    "                # Extract car features\n",
    "                try:\n",
    "                    desc = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.m-caslot__description\")))\n",
    "                    car_features = desc.find_elements(By.TAG_NAME, \"p\")\n",
    "                    details[\"Car_features\"] = car_features[1].text if len(car_features) > 1 else \"N/A\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting car features: {e}\")\n",
    "\n",
    "                # Extract service history\n",
    "                try:\n",
    "                    main_card = driver.find_element(By.CSS_SELECTOR, \"div.o-lot__features\")\n",
    "                    li_elements = main_card.find_elements(By.CSS_SELECTOR, 'ul.m-caslot__features li')\n",
    "                    details[\"car_Details\"] = [ele.text.strip() for ele in li_elements] if li_elements else \"N/A\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting service history: {e}\")\n",
    "\n",
    "                # Extract lot number and registration number\n",
    "                try:\n",
    "                    lot_center = driver.find_element(By.CSS_SELECTOR, \".m-lot-overview__lotno\").text\n",
    "                    lot_split = [lot_item.strip() for lot_item in lot_center.split(\" – \")]\n",
    "                    details[\"Lot\"] = lot_split[0] if len(lot_split) > 0 else \"N/A\"\n",
    "                    details[\"Reg_no\"] = lot_split[1] if len(lot_split) > 1 else \"N/A\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting lot and reg number: {e}\")\n",
    "\n",
    "                # Extract auction details\n",
    "                try:\n",
    "                    auc_details = driver.find_elements(By.CSS_SELECTOR, \"p.m-lot-overview__info\")\n",
    "                    details[\"Auction_details\"] = auc_details[0].text if auc_details else \"N/A\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting auction details: {e}\")\n",
    "\n",
    "                # Extract car images\n",
    "                try:\n",
    "                    img_elements = driver.find_elements(By.CSS_SELECTOR, 'div.slick-slide img')\n",
    "                    img_list = [img.get_attribute(\"src\") for img in img_elements] if img_elements else []\n",
    "                    details[\"Images\"] = \", \".join(img_list) if img_list else \"N/A\"\n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting car images: {e}\")\n",
    "\n",
    "                # Append car details to results\n",
    "                results.append(details)\n",
    "\n",
    "                # Navigate back to the main page\n",
    "                driver.back()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing car link {i}: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching car links: {e}\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(\"HOOBS.csv\", index=False)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# Run the scraper\n",
    "path = \"https://www.hobbsparker.co.uk/car-auctions/auction-dates/catalogue/?departmentId=8&saleTypeId=5&auctionId=456218\"\n",
    "scrape(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_make</th>\n",
       "      <th>Car_model</th>\n",
       "      <th>Veh_type</th>\n",
       "      <th>Car_colour</th>\n",
       "      <th>Car_features</th>\n",
       "      <th>car_Details</th>\n",
       "      <th>Lot</th>\n",
       "      <th>Reg_no</th>\n",
       "      <th>Auction_details</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>430d Gran Coupe M Sport Auto</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>Black</td>\n",
       "      <td>Current owner since March 2020, one former kee...</td>\n",
       "      <td>['3 Onboard oil services at 10k, 25k and last ...</td>\n",
       "      <td>LOT 111</td>\n",
       "      <td>YE19 VDK</td>\n",
       "      <td>To be sold at auction on Thursday 16th Jan 2025</td>\n",
       "      <td>https://res.cloudinary.com/hobbsparker/image/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fiat</td>\n",
       "      <td>500 E LA Prima</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>Grey</td>\n",
       "      <td>One owner from new. Air con, Leather, Rear cam...</td>\n",
       "      <td>['3 Main dealer service stamps, last in Sept 2...</td>\n",
       "      <td>LOT 116</td>\n",
       "      <td>GF71 FPV</td>\n",
       "      <td>To be sold at auction on Thursday 16th Jan 2025</td>\n",
       "      <td>https://res.cloudinary.com/hobbsparker/image/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Land Rover</td>\n",
       "      <td>Discovery HSE SDV6 Auto</td>\n",
       "      <td>Estate</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Current owner since Aug 21. 2 former keepers. ...</td>\n",
       "      <td>['7 service records (6 MD). Last recorded June...</td>\n",
       "      <td>LOT 118</td>\n",
       "      <td>KP68 MDN</td>\n",
       "      <td>To be sold at auction on Thursday 16th Jan 2025</td>\n",
       "      <td>https://res.cloudinary.com/hobbsparker/image/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Scirocco GT BL EDTN TDI B</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Current owner since Nov 17. 1 former keeper. A...</td>\n",
       "      <td>['9 MD service records. Last recorded July 202...</td>\n",
       "      <td>LOT 120</td>\n",
       "      <td>GJ17 VWP</td>\n",
       "      <td>To be sold at auction on Thursday 16th Jan 2025</td>\n",
       "      <td>https://res.cloudinary.com/hobbsparker/image/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Citroen</td>\n",
       "      <td>C5 Aircross C-Series ED PHEV A</td>\n",
       "      <td>Hatchback 5 Door</td>\n",
       "      <td>Grey</td>\n",
       "      <td>One owner from new. Air con, Leather, Sat Nav,...</td>\n",
       "      <td>['2 Main dealer dealer stamps in Jan 24 at 19k...</td>\n",
       "      <td>LOT 129</td>\n",
       "      <td>GF23 JNN</td>\n",
       "      <td>To be sold at auction on Thursday 16th Jan 2025</td>\n",
       "      <td>https://res.cloudinary.com/hobbsparker/image/f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Car_make                       Car_model          Veh_type Car_colour  \\\n",
       "0         BMW    430d Gran Coupe M Sport Auto             Coupe      Black   \n",
       "1        Fiat                  500 E LA Prima       Convertible       Grey   \n",
       "2  Land Rover         Discovery HSE SDV6 Auto            Estate       Grey   \n",
       "3  Volkswagen       Scirocco GT BL EDTN TDI B             Coupe       Blue   \n",
       "4     Citroen  C5 Aircross C-Series ED PHEV A  Hatchback 5 Door       Grey   \n",
       "\n",
       "                                        Car_features  \\\n",
       "0  Current owner since March 2020, one former kee...   \n",
       "1  One owner from new. Air con, Leather, Rear cam...   \n",
       "2  Current owner since Aug 21. 2 former keepers. ...   \n",
       "3  Current owner since Nov 17. 1 former keeper. A...   \n",
       "4  One owner from new. Air con, Leather, Sat Nav,...   \n",
       "\n",
       "                                         car_Details      Lot    Reg_no  \\\n",
       "0  ['3 Onboard oil services at 10k, 25k and last ...  LOT 111  YE19 VDK   \n",
       "1  ['3 Main dealer service stamps, last in Sept 2...  LOT 116  GF71 FPV   \n",
       "2  ['7 service records (6 MD). Last recorded June...  LOT 118  KP68 MDN   \n",
       "3  ['9 MD service records. Last recorded July 202...  LOT 120  GJ17 VWP   \n",
       "4  ['2 Main dealer dealer stamps in Jan 24 at 19k...  LOT 129  GF23 JNN   \n",
       "\n",
       "                                   Auction_details  \\\n",
       "0  To be sold at auction on Thursday 16th Jan 2025   \n",
       "1  To be sold at auction on Thursday 16th Jan 2025   \n",
       "2  To be sold at auction on Thursday 16th Jan 2025   \n",
       "3  To be sold at auction on Thursday 16th Jan 2025   \n",
       "4  To be sold at auction on Thursday 16th Jan 2025   \n",
       "\n",
       "                                              Images  \n",
       "0  https://res.cloudinary.com/hobbsparker/image/f...  \n",
       "1  https://res.cloudinary.com/hobbsparker/image/f...  \n",
       "2  https://res.cloudinary.com/hobbsparker/image/f...  \n",
       "3  https://res.cloudinary.com/hobbsparker/image/f...  \n",
       "4  https://res.cloudinary.com/hobbsparker/image/f...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"HOOBS.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_img = df[['Reg_no', 'Images']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "\n",
    "def download_images(data, main_folder=\"Images\"):\n",
    "    # Create the main folder if it doesn't exist\n",
    "    os.makedirs(main_folder, exist_ok=True)\n",
    "    \n",
    "    # Loop through each row to get the info\n",
    "    for index, row in data.iterrows():\n",
    "        reg_no = row[\"Reg_no\"]  # Separate registration numbers\n",
    "        image_urls = list(set(row[\"Images\"].split(\", \")))  # Split and deduplicate image URLs\n",
    "        \n",
    "        # Create a subfolder for the car registration number\n",
    "        reg_folder = os.path.join(main_folder, reg_no)  # Combine the main folder name and the registration number\n",
    "        os.makedirs(reg_folder, exist_ok=True)  # Create the subfolder if it doesn't exist\n",
    "        \n",
    "        print(f\"Processing Registration No: {reg_no}\")\n",
    "        \n",
    "        # Debug: Print unique URLs\n",
    "        print(f\"Image URLs: {image_urls}\")\n",
    "        \n",
    "        # Loop through the URLs of the current row\n",
    "        for idx, url in enumerate(image_urls):\n",
    "            url = url.strip()  # Remove extra spaces\n",
    "            if not url.startswith((\"http://\", \"https://\")):  # Check if the URL does not start with valid schemes\n",
    "                url = urljoin(\"https://\", url)  # Ensure the URLs start with https://...\n",
    "            \n",
    "            # Parse the URL\n",
    "            parsed_url = urlparse(url)\n",
    "\n",
    "            # Check if the parsed URL is valid\n",
    "            if not parsed_url.scheme or not parsed_url.netloc:\n",
    "                print(f\"Invalid URL skipped: {url}\")  # Skip invalid URLs\n",
    "                continue\n",
    "            \n",
    "            # Try downloading images\n",
    "            try:\n",
    "                # Download the image\n",
    "                response = requests.get(url, stream=True, timeout=10)  # Add a timeout to avoid infinite waits\n",
    "                response.raise_for_status()  # Raise an exception if the HTTP request fails\n",
    "                \n",
    "                # Extract the file name from the URL path\n",
    "                file_name = os.path.basename(parsed_url.path) or f\"image_{idx + 1}.jpg\"\n",
    "\n",
    "                # Ensure the file has a valid extension\n",
    "                file_extension = file_name.split(\".\")[-1].lower()\n",
    "                if file_extension not in [\"jpg\", \"jpeg\", \"png\", \"gif\", \"bmp\", \"webp\"]:\n",
    "                    file_name = f\"image_{idx + 1}.jpg\"  # Set a default extension\n",
    "                \n",
    "                # Construct the full path for the file\n",
    "                full_file_name = os.path.join(reg_folder, f\"{reg_no}_{idx + 1}_{file_name}\")\n",
    "                \n",
    "                # Check if the file already exists to avoid duplication\n",
    "                if os.path.exists(full_file_name):\n",
    "                    print(f\"File already exists, skipping: {full_file_name}\")\n",
    "                    continue\n",
    "                \n",
    "                # Save the image\n",
    "                with open(full_file_name, 'wb') as f:\n",
    "                    for chunk in response.iter_content(1024):  # Reads the response in 1KB chunks\n",
    "                        f.write(chunk)\n",
    "                \n",
    "                print(f\"Downloaded: {full_file_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {url} for {reg_no}: {e}\")\n",
    "            finally:\n",
    "                # Ensure the response is closed\n",
    "                response.close()\n",
    "# Call the function\n",
    "download_images(reg_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
